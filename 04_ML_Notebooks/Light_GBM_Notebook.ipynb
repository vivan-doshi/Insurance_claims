{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vivan/miniconda3/envs/DSO530/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.feature_selection import RFECV\n",
    "from lightgbm import LGBMRegressor, LGBMClassifier\n",
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change file location to Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "head, tail = os.path.split(os.getcwd())\n",
    "os.chdir(os.path.join(head,'01_Data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['insurance_train.csv',\n",
       " 'cleaned_test.csv',\n",
       " 'cleaned_data.parquet',\n",
       " 'cleaned_data.csv',\n",
       " 'cleaned_test.parquet',\n",
       " 'insurance_test.csv',\n",
       " 'cleaned_test.pkl',\n",
       " 'cleaned_data.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Start_Date_Contract</th>\n",
       "      <th>Date_Last_Renewal</th>\n",
       "      <th>Date_Next_Renewal</th>\n",
       "      <th>Date_Of_Birth</th>\n",
       "      <th>Date_Of_DL_Issuance</th>\n",
       "      <th>Issurance_Broker_Agent_Channel</th>\n",
       "      <th>Years_Associates</th>\n",
       "      <th>Total_Policies_Entity</th>\n",
       "      <th>Max_Policy_Simultaneous_Force</th>\n",
       "      <th>...</th>\n",
       "      <th>Non_Continuation_Insurance_Flag</th>\n",
       "      <th>New_License</th>\n",
       "      <th>Car_Age_Cat</th>\n",
       "      <th>Ratio_Premium_Car_Value</th>\n",
       "      <th>Power_Wt_Ratio</th>\n",
       "      <th>Customer_Loyalty</th>\n",
       "      <th>New_Bhp_Risk</th>\n",
       "      <th>Years_Driving_At_Start_Date</th>\n",
       "      <th>Young_Driver</th>\n",
       "      <th>Young_Bhp_Risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34429</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>1996-08-29</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Old</td>\n",
       "      <td>0.044787</td>\n",
       "      <td>0.072115</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5552</td>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>1992-04-30</td>\n",
       "      <td>2010-08-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0.019446</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47700</td>\n",
       "      <td>2003-01-08</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1972-03-23</td>\n",
       "      <td>1998-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Old</td>\n",
       "      <td>0.015644</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25425</td>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1946-03-05</td>\n",
       "      <td>1964-08-07</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Standard</td>\n",
       "      <td>0.010544</td>\n",
       "      <td>0.070565</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4727</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>1973-04-25</td>\n",
       "      <td>1998-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Old</td>\n",
       "      <td>0.020250</td>\n",
       "      <td>0.047004</td>\n",
       "      <td>3.80</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID Start_Date_Contract Date_Last_Renewal Date_Next_Renewal  \\\n",
       "0  34429          2017-06-01        2017-06-01        2018-06-01   \n",
       "1   5552          2016-09-19        2018-09-19        2019-09-19   \n",
       "2  47700          2003-01-08        2018-01-08        2019-01-08   \n",
       "3  25425          2015-10-01        2018-10-01        2019-10-01   \n",
       "4   4727          2017-01-26        2018-01-26        2019-01-26   \n",
       "\n",
       "  Date_Of_Birth Date_Of_DL_Issuance  Issurance_Broker_Agent_Channel  \\\n",
       "0    1996-08-29          2016-05-31                               0   \n",
       "1    1992-04-30          2010-08-03                               0   \n",
       "2    1972-03-23          1998-02-01                               1   \n",
       "3    1946-03-05          1964-08-07                               0   \n",
       "4    1973-04-25          1998-07-24                               0   \n",
       "\n",
       "   Years_Associates  Total_Policies_Entity  Max_Policy_Simultaneous_Force  \\\n",
       "0                 1                      1                              1   \n",
       "1                 3                      1                              1   \n",
       "2                20                      2                              2   \n",
       "3                 8                      2                              3   \n",
       "4                 9                      1                              1   \n",
       "\n",
       "   ...  Non_Continuation_Insurance_Flag  New_License  Car_Age_Cat  \\\n",
       "0  ...                                1            0          Old   \n",
       "1  ...                                0            0     Standard   \n",
       "2  ...                                0            0          Old   \n",
       "3  ...                                0            0     Standard   \n",
       "4  ...                                0            0          Old   \n",
       "\n",
       "   Ratio_Premium_Car_Value  Power_Wt_Ratio  Customer_Loyalty  New_Bhp_Risk  \\\n",
       "0                 0.044787        0.072115              1.00             0   \n",
       "1                 0.019446        0.085837              1.70             0   \n",
       "2                 0.015644        0.076923              8.15             0   \n",
       "3                 0.010544        0.070565              4.15             0   \n",
       "4                 0.020250        0.047004              3.80             0   \n",
       "\n",
       "   Years_Driving_At_Start_Date  Young_Driver  Young_Bhp_Risk  \n",
       "0                            1             1               0  \n",
       "1                            6             0               0  \n",
       "2                            5             0               0  \n",
       "3                           51             0               0  \n",
       "4                           19             0               0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_parquet('cleaned_data.parquet')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Start_Date_Contract', 'Date_Last_Renewal', 'Date_Next_Renewal',\n",
       "       'Date_Of_Birth', 'Date_Of_DL_Issuance',\n",
       "       'Issurance_Broker_Agent_Channel', 'Years_Associates',\n",
       "       'Total_Policies_Entity', 'Max_Policy_Simultaneous_Force',\n",
       "       'Max_Product_Simultaneous_Held', 'Policies_Terminated_Non_Payment',\n",
       "       'Half_Yearly_Payment_Method', 'Premium_Amt_Current_Yr',\n",
       "       'Total_Cost_Claims_Current_Yr', 'Total_Number_Claims_Current_Yr',\n",
       "       'Total_Number_Claims_Entire_Duration',\n",
       "       'Ratio_Claims_Total_Duration_Force',\n",
       "       'Motorbikes_Vans_Cars_Agricultural', 'Rural_Urban_Flag',\n",
       "       'Multiple_Drivers_Regular_Flag', 'Yr_Vehicle_Registration',\n",
       "       'Vehicle_Power_HP', 'Cylinder_Capacity', 'Market_Value_EOY19',\n",
       "       'Vehicle_Doors', 'Energy_Source', 'Vehicle_Wt_Kg', 'Loss_Cost',\n",
       "       'Historically_Adjusted_Loss_Cost', 'Claim_Status', 'Age',\n",
       "       'Years_Driving', 'Car_Age', 'Time_Since_Last_Renewal',\n",
       "       'Non_Payment_Termination', 'Non_Continuation_Insurance_Flag',\n",
       "       'New_License', 'Car_Age_Cat', 'Ratio_Premium_Car_Value',\n",
       "       'Power_Wt_Ratio', 'Customer_Loyalty', 'New_Bhp_Risk',\n",
       "       'Years_Driving_At_Start_Date', 'Young_Driver', 'Young_Bhp_Risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Start_Date_Contract', 'Date_Last_Renewal', 'Date_Next_Renewal',\n",
       "       'Date_Of_Birth', 'Date_Of_DL_Issuance',\n",
       "       'Issurance_Broker_Agent_Channel', 'Years_Associates',\n",
       "       'Total_Policies_Entity', 'Max_Policy_Simultaneous_Force',\n",
       "       'Max_Product_Simultaneous_Held', 'Policies_Terminated_Non_Payment',\n",
       "       'Half_Yearly_Payment_Method', 'Premium_Amt_Current_Yr',\n",
       "       'Motorbikes_Vans_Cars_Agricultural', 'Rural_Urban_Flag',\n",
       "       'Multiple_Drivers_Regular_Flag', 'Yr_Vehicle_Registration',\n",
       "       'Vehicle_Power_HP', 'Cylinder_Capacity', 'Market_Value_EOY19',\n",
       "       'Vehicle_Doors', 'Energy_Source', 'Vehicle_Wt_Kg', 'Age',\n",
       "       'Years_Driving', 'Car_Age', 'Time_Since_Last_Renewal',\n",
       "       'Non_Payment_Termination', 'Non_Continuation_Insurance_Flag',\n",
       "       'New_License', 'Car_Age_Cat', 'Ratio_Premium_Car_Value',\n",
       "       'Power_Wt_Ratio', 'Customer_Loyalty', 'New_Bhp_Risk',\n",
       "       'Years_Driving_At_Start_Date', 'Young_Driver', 'Young_Bhp_Risk'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X.drop(columns=['ID', 'Total_Cost_Claims_Current_Yr', 'Total_Number_Claims_Current_Yr',\n",
    "                    'Total_Number_Claims_Entire_Duration', 'Ratio_Claims_Total_Duration_Force',\n",
    "                    'Loss_Cost', 'Historically_Adjusted_Loss_Cost', 'Claim_Status'])\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_reg = data[['Loss_Cost','Historically_Adjusted_Loss_Cost']]\n",
    "Y_class = data[['Claim_Status']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing the X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Start_Date_Contract                    0\n",
       "Date_Last_Renewal                      0\n",
       "Date_Next_Renewal                      0\n",
       "Date_Of_Birth                          0\n",
       "Date_Of_DL_Issuance                    0\n",
       "Issurance_Broker_Agent_Channel         0\n",
       "Years_Associates                       0\n",
       "Total_Policies_Entity                  0\n",
       "Max_Policy_Simultaneous_Force          0\n",
       "Max_Product_Simultaneous_Held          0\n",
       "Policies_Terminated_Non_Payment        0\n",
       "Half_Yearly_Payment_Method             0\n",
       "Premium_Amt_Current_Yr                 0\n",
       "Motorbikes_Vans_Cars_Agricultural      0\n",
       "Rural_Urban_Flag                       0\n",
       "Multiple_Drivers_Regular_Flag          0\n",
       "Yr_Vehicle_Registration                0\n",
       "Vehicle_Power_HP                       0\n",
       "Cylinder_Capacity                      0\n",
       "Market_Value_EOY19                     0\n",
       "Vehicle_Doors                          0\n",
       "Energy_Source                        593\n",
       "Vehicle_Wt_Kg                          0\n",
       "Age                                    0\n",
       "Years_Driving                          0\n",
       "Car_Age                                0\n",
       "Time_Since_Last_Renewal                0\n",
       "Non_Payment_Termination                0\n",
       "Non_Continuation_Insurance_Flag        0\n",
       "New_License                            0\n",
       "Car_Age_Cat                            0\n",
       "Ratio_Premium_Car_Value                0\n",
       "Power_Wt_Ratio                         0\n",
       "Customer_Loyalty                       0\n",
       "New_Bhp_Risk                           0\n",
       "Years_Driving_At_Start_Date            0\n",
       "Young_Driver                           0\n",
       "Young_Bhp_Risk                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy_Source                        593\n",
       "Loss_Cost                          33300\n",
       "Historically_Adjusted_Loss_Cost    33300\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()[data.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim_Status\n",
       "0    564\n",
       "1     29\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Energy_Source'].isna(),'Claim_Status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill the X['Energy_Source'] with other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Energy_Source\n",
       "D        23074\n",
       "P        13784\n",
       "Other      593\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['Energy_Source'] = X['Energy_Source'].fillna('Other')\n",
    "X['Energy_Source'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37451 entries, 0 to 37450\n",
      "Data columns (total 38 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   Start_Date_Contract                37451 non-null  datetime64[ns]\n",
      " 1   Date_Last_Renewal                  37451 non-null  datetime64[ns]\n",
      " 2   Date_Next_Renewal                  37451 non-null  datetime64[ns]\n",
      " 3   Date_Of_Birth                      37451 non-null  datetime64[ns]\n",
      " 4   Date_Of_DL_Issuance                37451 non-null  datetime64[ns]\n",
      " 5   Issurance_Broker_Agent_Channel     37451 non-null  int64         \n",
      " 6   Years_Associates                   37451 non-null  int64         \n",
      " 7   Total_Policies_Entity              37451 non-null  int64         \n",
      " 8   Max_Policy_Simultaneous_Force      37451 non-null  int64         \n",
      " 9   Max_Product_Simultaneous_Held      37451 non-null  int64         \n",
      " 10  Policies_Terminated_Non_Payment    37451 non-null  int64         \n",
      " 11  Half_Yearly_Payment_Method         37451 non-null  int64         \n",
      " 12  Premium_Amt_Current_Yr             37451 non-null  float64       \n",
      " 13  Motorbikes_Vans_Cars_Agricultural  37451 non-null  int64         \n",
      " 14  Rural_Urban_Flag                   37451 non-null  int64         \n",
      " 15  Multiple_Drivers_Regular_Flag      37451 non-null  int64         \n",
      " 16  Yr_Vehicle_Registration            37451 non-null  int64         \n",
      " 17  Vehicle_Power_HP                   37451 non-null  int64         \n",
      " 18  Cylinder_Capacity                  37451 non-null  int64         \n",
      " 19  Market_Value_EOY19                 37451 non-null  float64       \n",
      " 20  Vehicle_Doors                      37451 non-null  int64         \n",
      " 21  Energy_Source                      37451 non-null  object        \n",
      " 22  Vehicle_Wt_Kg                      37451 non-null  int64         \n",
      " 23  Age                                37451 non-null  int32         \n",
      " 24  Years_Driving                      37451 non-null  int32         \n",
      " 25  Car_Age                            37451 non-null  int64         \n",
      " 26  Time_Since_Last_Renewal            37451 non-null  int32         \n",
      " 27  Non_Payment_Termination            37451 non-null  int64         \n",
      " 28  Non_Continuation_Insurance_Flag    37451 non-null  int64         \n",
      " 29  New_License                        37451 non-null  int64         \n",
      " 30  Car_Age_Cat                        37451 non-null  category      \n",
      " 31  Ratio_Premium_Car_Value            37451 non-null  float64       \n",
      " 32  Power_Wt_Ratio                     37451 non-null  float64       \n",
      " 33  Customer_Loyalty                   37451 non-null  float64       \n",
      " 34  New_Bhp_Risk                       37451 non-null  int64         \n",
      " 35  Years_Driving_At_Start_Date        37451 non-null  int32         \n",
      " 36  Young_Driver                       37451 non-null  int64         \n",
      " 37  Young_Bhp_Risk                     37451 non-null  int64         \n",
      "dtypes: category(1), datetime64[ns](5), float64(5), int32(4), int64(22), object(1)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start_Date_Contract</th>\n",
       "      <th>Date_Last_Renewal</th>\n",
       "      <th>Date_Next_Renewal</th>\n",
       "      <th>Date_Of_Birth</th>\n",
       "      <th>Date_Of_DL_Issuance</th>\n",
       "      <th>Issurance_Broker_Agent_Channel</th>\n",
       "      <th>Years_Associates</th>\n",
       "      <th>Total_Policies_Entity</th>\n",
       "      <th>Max_Policy_Simultaneous_Force</th>\n",
       "      <th>Max_Product_Simultaneous_Held</th>\n",
       "      <th>...</th>\n",
       "      <th>Years_Driving_At_Start_Date</th>\n",
       "      <th>Young_Driver</th>\n",
       "      <th>Young_Bhp_Risk</th>\n",
       "      <th>Car_Age_Cat_New</th>\n",
       "      <th>Car_Age_Cat_Recent</th>\n",
       "      <th>Car_Age_Cat_Standard</th>\n",
       "      <th>Car_Age_Cat_Old</th>\n",
       "      <th>Energy_Source_D</th>\n",
       "      <th>Energy_Source_Other</th>\n",
       "      <th>Energy_Source_P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>1996-08-29</td>\n",
       "      <td>2016-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-19</td>\n",
       "      <td>2018-09-19</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>1992-04-30</td>\n",
       "      <td>2010-08-03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-08</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>2019-01-08</td>\n",
       "      <td>1972-03-23</td>\n",
       "      <td>1998-02-01</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-10-01</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>1946-03-05</td>\n",
       "      <td>1964-08-07</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>1973-04-25</td>\n",
       "      <td>1998-07-24</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Start_Date_Contract Date_Last_Renewal Date_Next_Renewal Date_Of_Birth  \\\n",
       "0          2017-06-01        2017-06-01        2018-06-01    1996-08-29   \n",
       "1          2016-09-19        2018-09-19        2019-09-19    1992-04-30   \n",
       "2          2003-01-08        2018-01-08        2019-01-08    1972-03-23   \n",
       "3          2015-10-01        2018-10-01        2019-10-01    1946-03-05   \n",
       "4          2017-01-26        2018-01-26        2019-01-26    1973-04-25   \n",
       "\n",
       "  Date_Of_DL_Issuance  Issurance_Broker_Agent_Channel  Years_Associates  \\\n",
       "0          2016-05-31                               0                 1   \n",
       "1          2010-08-03                               0                 3   \n",
       "2          1998-02-01                               1                20   \n",
       "3          1964-08-07                               0                 8   \n",
       "4          1998-07-24                               0                 9   \n",
       "\n",
       "   Total_Policies_Entity  Max_Policy_Simultaneous_Force  \\\n",
       "0                      1                              1   \n",
       "1                      1                              1   \n",
       "2                      2                              2   \n",
       "3                      2                              3   \n",
       "4                      1                              1   \n",
       "\n",
       "   Max_Product_Simultaneous_Held  ...  Years_Driving_At_Start_Date  \\\n",
       "0                              1  ...                            1   \n",
       "1                              1  ...                            6   \n",
       "2                              1  ...                            5   \n",
       "3                              1  ...                           51   \n",
       "4                              1  ...                           19   \n",
       "\n",
       "   Young_Driver  Young_Bhp_Risk  Car_Age_Cat_New  Car_Age_Cat_Recent  \\\n",
       "0             1               0                0                   0   \n",
       "1             0               0                0                   0   \n",
       "2             0               0                0                   0   \n",
       "3             0               0                0                   0   \n",
       "4             0               0                0                   0   \n",
       "\n",
       "   Car_Age_Cat_Standard  Car_Age_Cat_Old  Energy_Source_D  \\\n",
       "0                     0                1                0   \n",
       "1                     1                0                1   \n",
       "2                     0                1                0   \n",
       "3                     1                0                1   \n",
       "4                     0                1                0   \n",
       "\n",
       "   Energy_Source_Other  Energy_Source_P  \n",
       "0                    0                1  \n",
       "1                    0                0  \n",
       "2                    0                1  \n",
       "3                    0                0  \n",
       "4                    0                1  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.get_dummies(X, columns=['Car_Age_Cat', 'Energy_Source'], dtype=int, drop_first=False)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Car_Age_Cat_New          2159\n",
       "Car_Age_Cat_Recent       3402\n",
       "Car_Age_Cat_Standard    16978\n",
       "Car_Age_Cat_Old         14912\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[['Car_Age_Cat_New','Car_Age_Cat_Recent','Car_Age_Cat_Standard','Car_Age_Cat_Old']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['Car_Age_Cat_New', 'Energy_Source_Other'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to drop time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.drop(columns=['Start_Date_Contract','Date_Last_Renewal','Date_Next_Renewal','Date_Of_Birth','Date_Of_DL_Issuance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixing Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_reg = Y_reg.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loss_Cost   Historically_Adjusted_Loss_Cost\n",
       "0.000       0.00000                            33300\n",
       "882.000     882.00000                             40\n",
       "            1764.00000                            10\n",
       "            1746.36000                             9\n",
       "            1755.18000                             8\n",
       "                                               ...  \n",
       "96.150      192.30000                              1\n",
       "96.300      135.78300                              1\n",
       "96.335      230.24065                              1\n",
       "96.410      157.14830                              1\n",
       "118142.590  236285.18000                           1\n",
       "Name: count, Length: 3906, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_reg.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to split the data appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to stratify it while splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7491, 36)\n",
      "(29960, 36)\n",
      "(7491, 1)\n",
      "(29960, 1)\n"
     ]
    }
   ],
   "source": [
    "X_class_train, X_class_test, Y_class_train, Y_class_test = train_test_split(\n",
    "    X, Y_class,\n",
    "    test_size=0.2,\n",
    "    stratify=Y_class,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(X_class_test.shape)\n",
    "print(X_class_train.shape)\n",
    "print(Y_class_test.shape)\n",
    "print(Y_class_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim_Status\n",
       "0               0.889152\n",
       "1               0.110848\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Claim_Status\n",
       "0               0.8892\n",
       "1               0.1108\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Y_class_train.value_counts(normalize=True))\n",
    "display(Y_class_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For regressors we need to mention 0 before stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loss_Cost\n",
       "1    33300\n",
       "0     4151\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using Loss Cost as HALC might have some 0\n",
    "zero_flag = (Y_reg['Loss_Cost'] == 0).astype(int)\n",
    "zero_flag.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reg_train, X_reg_test, Y_reg_train, Y_reg_test = train_test_split(\n",
    "    X, Y_reg,\n",
    "    test_size=0.2,\n",
    "    stratify=zero_flag,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7491, 36)\n",
      "(29960, 36)\n",
      "(7491, 2)\n",
      "(29960, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_reg_test.shape)\n",
    "print(X_reg_train.shape)\n",
    "print(Y_reg_test.shape)\n",
    "print(Y_reg_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891522029372496"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8892003737818716"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(len(Y_reg_train[Y_reg_train['Loss_Cost']==0])/len(Y_reg_train))\n",
    "display(len(Y_reg_test[Y_reg_test['Loss_Cost']==0])/len(Y_reg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stratify_bins(y, n_bins=10):\n",
    "    return pd.qcut(y, q=n_bins, duplicates='drop', labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_with_rfecv(X, y, objective=\"regression\"):\n",
    "    estimator = (\n",
    "        LGBMRegressor(random_state=42, n_estimators=100, learning_rate=0.1)\n",
    "        if objective == \"regression\"\n",
    "        else LGBMClassifier(random_state=42)\n",
    "    )\n",
    "    scoring = \"neg_root_mean_squared_error\" if objective == \"regression\" else \"roc_auc\"\n",
    "\n",
    "    if objective == \"regression\":\n",
    "        y_strat = make_stratify_bins(y, n_bins=5)\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rfecv = RFECV(estimator=estimator, step=1, cv=cv.split(X, y_strat), scoring=scoring, min_features_to_select=5)\n",
    "    else:\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        rfecv = RFECV(estimator=estimator, step=1, cv=cv, scoring=scoring, min_features_to_select=5)\n",
    "\n",
    "    rfecv.fit(X, y)\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(range(1, len(rfecv.cv_results_[\"mean_test_score\"]) + 1), rfecv.cv_results_[\"mean_test_score\"])\n",
    "    plt.xlabel(\"Number of Features Selected\")\n",
    "    plt.ylabel(\"Cross-Validation Score\")\n",
    "    plt.title(\"RFECV Performance by Number of Features\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    selected_features = X.columns[rfecv.support_].tolist()\n",
    "    print(f\"Selected {len(selected_features)} features out of {X.shape[1]}\")\n",
    "    return X[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to use on optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))\n",
    "\n",
    "def tune_lightgbm(X, y, folds, objective, scorer, use_gpu=False, show_plots=False):\n",
    "    \"\"\"\n",
    "    X : predictors (DataFrame)\n",
    "    y : target (Series)\n",
    "    folds : a StratifiedKFold object\n",
    "    objective : \"tweedie\" or \"binary\"\n",
    "    scorer : \"rmse\" or \"auc\"\n",
    "    use_gpu : Set to True to enable GPU (default False)\n",
    "    show_plots : If True, displays Optuna visualizations (default False)\n",
    "    \"\"\"\n",
    "\n",
    "    direction = \"minimize\" if scorer == \"rmse\" else \"maximize\"\n",
    "\n",
    "    if scorer == \"rmse\":\n",
    "        y_strat = make_stratify_bins(y)\n",
    "    else:\n",
    "        y_strat = y\n",
    "\n",
    "    def objective_fn(trial):\n",
    "        params = {\n",
    "            \"objective\": objective,\n",
    "            \"learning_rate\": trial.suggest_float(\"lr\", 0.01, 0.2, log=True),\n",
    "            \"num_leaves\": trial.suggest_int(\"leaves\", 16, 255),\n",
    "            \"feature_fraction\": trial.suggest_float(\"ff\", 0.5, 1.0),\n",
    "            \"bagging_fraction\": trial.suggest_float(\"bf\", 0.5, 1.0),\n",
    "            \"bagging_freq\": 1,\n",
    "            \"max_depth\": -1,\n",
    "            \"lambda_l1\": trial.suggest_float(\"l1\", 0.0, 5.0),\n",
    "            \"lambda_l2\": trial.suggest_float(\"l2\", 0.0, 5.0),\n",
    "            \"random_state\": 42,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "\n",
    "        if use_gpu:\n",
    "            params[\"device\"] = \"gpu\"\n",
    "            params[\"gpu_platform_id\"] = 0\n",
    "            params[\"gpu_device_id\"] = 0\n",
    "\n",
    "        if objective == \"tweedie\":\n",
    "            params[\"tweedie_variance_power\"] = trial.suggest_float(\"p\", 1.1, 1.9)\n",
    "        if objective == \"binary\":\n",
    "            params[\"is_unbalance\"] = True\n",
    "\n",
    "        scores = []\n",
    "\n",
    "        for tr_idx, val_idx in folds.split(X, y_strat):\n",
    "            X_tr, X_val = X.iloc[tr_idx], X.iloc[val_idx]\n",
    "            y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = (\n",
    "                LGBMRegressor(**params, n_estimators=5000)\n",
    "                if objective == \"tweedie\"\n",
    "                else LGBMClassifier(**params, n_estimators=5000)\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                X_tr, y_tr,\n",
    "                eval_set=[(X_val, y_val)],\n",
    "                eval_metric=scorer\n",
    "            )\n",
    "\n",
    "            preds = model.predict(X_val)\n",
    "\n",
    "            if scorer == \"rmse\":\n",
    "                scores.append(rmse(y_val, preds))\n",
    "            else:\n",
    "                scores.append(roc_auc_score(y_val, preds))\n",
    "\n",
    "        return np.mean(scores)\n",
    "\n",
    "    study = optuna.create_study(direction=direction)\n",
    "    study.optimize(objective_fn, n_trials=60, timeout=1800, show_progress_bar=True)\n",
    "\n",
    "    if show_plots:\n",
    "        try:\n",
    "            from optuna.visualization.matplotlib import plot_optimization_history, plot_param_importances\n",
    "\n",
    "            plot_optimization_history(study)\n",
    "            plt.title(\"Optuna Optimization History\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            plot_param_importances(study)\n",
    "            plt.title(\"Hyperparameter Importance\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        except ImportError:\n",
    "            print(\"Install matplotlib and optuna[visualization] to enable plots.\")\n",
    "\n",
    "    return study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we need to select variables and tune each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2367\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2365\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2365\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005338 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2363\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2363\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2361\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2359\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001445 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002489 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2294\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003211 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2285\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2281\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002119 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2279\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2277\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003907 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2275\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2269\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001442 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2267\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2262\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001361 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2247\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2232\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2226\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000258 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2185\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1946\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1885\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1690\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1464\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1401\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000671 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1146\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1084\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 63.786253\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2372\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003547 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2370\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2370\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2368\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2368\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2366\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001839 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2364\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001914 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2302\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2300\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001824 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2293\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001507 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2289\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2285\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2274\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2272\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2268\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000355 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2253\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2213\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2198\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2192\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000974 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2187\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2127\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1891\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002338 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1661\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1464\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1401\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1339\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1084\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 68.324199\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2370\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2368\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003476 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2368\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2366\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2366\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2364\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001215 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2362\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2300\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001453 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2284\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001260 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024170 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001028 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2278\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2276\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2274\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2272\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000231 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2266\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2250\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2243\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2202\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2186\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000182 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2181\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2118\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1890\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1657\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000130 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1460\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1398\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1335\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 65.052345\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2367\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2365\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2365\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001656 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2363\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001521 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2363\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2361\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2359\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001369 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2295\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2290\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2288\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2286\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001281 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2284\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2282\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2280\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2278\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2276\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000735 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2270\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000760 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2265\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000192 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2247\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2240\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2199\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000166 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2183\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2178\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000148 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2115\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1890\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1694\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000125 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1632\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000098 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1339\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000087 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1084\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 67.798146\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2368\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2366\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2366\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2364\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002151 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2364\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2362\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001183 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2360\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2298\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2296\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2291\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2289\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2287\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2285\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2283\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2281\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001168 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2266\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2260\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000955 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2255\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2253\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2251\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2249\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2208\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2201\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2185\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000163 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2180\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000212 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2120\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000117 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1888\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1657\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 9\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1462\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1400\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 7\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1338\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 23968, number of used features: 5\n",
      "[LightGBM] [Info] Start training from score 66.788191\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2386\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001822 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2384\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2384\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2382\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2382\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2380\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001772 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2378\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2314\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2312\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2310\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001703 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2303\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2301\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2299\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001342 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2297\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 66.349827\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2292\n",
      "[LightGBM] [Info] Number of data points in the train set: 29960, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 66.349827\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 18:14:21,145] A new study created in memory with name: no-name-cb1ad74e-17df-4540-817d-4cbbe989b254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 21 features out of 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 535.055:   2%|▏         | 1/60 [01:22<1:21:34, 82.95s/it, 82.95/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 18:15:44,130] Trial 0 finished with value: 535.054806750114 and parameters: {'lr': 0.19306929396345077, 'leaves': 104, 'ff': 0.636623931835776, 'bf': 0.6262593530243084, 'l1': 2.5204095207927772, 'l2': 2.510053713490958, 'p': 1.4975419592159405}. Best is trial 0 with value: 535.054806750114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 535.055:   3%|▎         | 2/60 [03:46<1:54:34, 118.53s/it, 226.39/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 18:18:07,570] Trial 1 finished with value: 535.5149658199174 and parameters: {'lr': 0.02331431247858981, 'leaves': 223, 'ff': 0.9485100083538553, 'bf': 0.6053778111542487, 'l1': 3.802959661706727, 'l2': 2.322669377490504, 'p': 1.8258382018126025}. Best is trial 0 with value: 535.054806750114.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 534.811:   5%|▌         | 3/60 [05:23<1:43:06, 108.53s/it, 323.02/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 18:19:44,196] Trial 2 finished with value: 534.810847432849 and parameters: {'lr': 0.09780813240193546, 'leaves': 113, 'ff': 0.7876244068775411, 'bf': 0.6906477891430114, 'l1': 4.100878473995806, 'l2': 4.982148686200802, 'p': 1.2464704797803583}. Best is trial 2 with value: 534.810847432849.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 532.527:   7%|▋         | 4/60 [05:56<1:13:46, 79.05s/it, 356.88/1800 seconds] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 18:20:18,057] Trial 3 finished with value: 532.5266918947331 and parameters: {'lr': 0.012598112093564182, 'leaves': 23, 'ff': 0.5346220957038518, 'bf': 0.578361207965113, 'l1': 4.941590968297255, 'l2': 1.7399265467748048, 'p': 1.679788830644572}. Best is trial 3 with value: 532.5266918947331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 532.527:   8%|▊         | 5/60 [09:01<1:47:23, 117.15s/it, 541.58/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 18:23:22,760] Trial 4 finished with value: 535.3286378332223 and parameters: {'lr': 0.010287955612741848, 'leaves': 200, 'ff': 0.8516374271460742, 'bf': 0.5912942848037792, 'l1': 4.650779316170289, 'l2': 1.5871481954878304, 'p': 1.7180733708585931}. Best is trial 3 with value: 532.5266918947331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 532.527:  10%|█         | 6/60 [3:54:01<35:06:14, 2340.27s/it, 14041.65/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 22:08:22,815] Trial 5 finished with value: 535.4599569031412 and parameters: {'lr': 0.04041935550215148, 'leaves': 216, 'ff': 0.5117521860718139, 'bf': 0.9780002924434182, 'l1': 0.7468018962998701, 'l2': 0.1670729523278125, 'p': 1.7696986850662628}. Best is trial 3 with value: 532.5266918947331.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# a) Pipeline for Loss_Cost (LC)\n",
    "X_lc_selected = select_features_with_rfecv(X_reg_train, Y_reg_train[\"Loss_Cost\"], objective=\"regression\")\n",
    "skf_lc = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_lc_params = tune_lightgbm(X_lc_selected, Y_reg_train[\"Loss_Cost\"], skf_lc, \"tweedie\", \"rmse\")\n",
    "X_lc_test_selected = X_reg_test[X_lc_selected.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 22:48:44,252] A new study created in memory with name: no-name-ce76e19e-1a35-44f1-90e0-3554f63b6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 22 features out of 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1160.68:   2%|▏         | 1/60 [16:36<16:20:02, 996.65s/it, 996.65/1800 seconds]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 23:05:20,899] Trial 0 finished with value: 1160.6768214673475 and parameters: {'lr': 0.044212420793623, 'leaves': 213, 'ff': 0.5299239875213406, 'bf': 0.519872066593496, 'l1': 0.8278150070057722, 'l2': 1.1578440386918198, 'p': 1.4812796575997766}. Best is trial 0 with value: 1160.6768214673475.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 1160.68:   2%|▏         | 1/60 [1:27:06<85:39:50, 5226.96s/it, 996.65/1800 seconds]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[W 2025-04-20 00:15:51,189] Trial 1 failed with parameters: {'lr': 0.19060737950020457, 'leaves': 53, 'ff': 0.8621366736049889, 'bf': 0.9828919178880604, 'l1': 1.521195887195268, 'l2': 4.232151124887462, 'p': 1.6534481031915238} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/vivan/miniconda3/envs/DSO530/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/l5/9tzh8xvn4c9bb2qc2r3pkqtc0000gn/T/ipykernel_64826/4163601309.py\", line 59, in objective_fn\n",
      "    model.fit(\n",
      "  File \"/Users/vivan/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/sklearn.py\", line 1398, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/vivan/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/sklearn.py\", line 1049, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"/Users/vivan/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/engine.py\", line 322, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"/Users/vivan/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/basic.py\", line 4155, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-04-20 00:15:51,213] Trial 1 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m X_halc_selected = select_features_with_rfecv(X_reg_train, Y_reg_train[\u001b[33m\"\u001b[39m\u001b[33mHistorically_Adjusted_Loss_Cost\u001b[39m\u001b[33m\"\u001b[39m], objective=\u001b[33m\"\u001b[39m\u001b[33mregression\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m skf_halc = StratifiedKFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m best_halc_params = tune_lightgbm(X_halc_selected, Y_reg_train[\u001b[33m\"\u001b[39m\u001b[33mHistorically_Adjusted_Loss_Cost\u001b[39m\u001b[33m\"\u001b[39m], skf_halc, \u001b[33m\"\u001b[39m\u001b[33mtweedie\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrmse\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m X_halc_test_selected = X_reg_test[X_halc_selected.columns]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mtune_lightgbm\u001b[39m\u001b[34m(X, y, folds, objective, scorer, use_gpu, show_plots)\u001b[39m\n\u001b[32m     72\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.mean(scores)\n\u001b[32m     74\u001b[39m study = optuna.create_study(direction=direction)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m study.optimize(objective_fn, n_trials=\u001b[32m60\u001b[39m, timeout=\u001b[32m1800\u001b[39m, show_progress_bar=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m show_plots:\n\u001b[32m     78\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/optuna/study/study.py:475\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    373\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    375\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    382\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    383\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    384\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    385\u001b[39m \n\u001b[32m    386\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    473\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    474\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     _optimize(\n\u001b[32m    476\u001b[39m         study=\u001b[38;5;28mself\u001b[39m,\n\u001b[32m    477\u001b[39m         func=func,\n\u001b[32m    478\u001b[39m         n_trials=n_trials,\n\u001b[32m    479\u001b[39m         timeout=timeout,\n\u001b[32m    480\u001b[39m         n_jobs=n_jobs,\n\u001b[32m    481\u001b[39m         catch=\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[32m    482\u001b[39m         callbacks=callbacks,\n\u001b[32m    483\u001b[39m         gc_after_trial=gc_after_trial,\n\u001b[32m    484\u001b[39m         show_progress_bar=show_progress_bar,\n\u001b[32m    485\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m         _optimize_sequential(\n\u001b[32m     64\u001b[39m             study,\n\u001b[32m     65\u001b[39m             func,\n\u001b[32m     66\u001b[39m             n_trials,\n\u001b[32m     67\u001b[39m             timeout,\n\u001b[32m     68\u001b[39m             catch,\n\u001b[32m     69\u001b[39m             callbacks,\n\u001b[32m     70\u001b[39m             gc_after_trial,\n\u001b[32m     71\u001b[39m             reseed_sampler_rng=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     72\u001b[39m             time_start=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     73\u001b[39m             progress_bar=progress_bar,\n\u001b[32m     74\u001b[39m         )\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     frozen_trial = _run_trial(study, func, catch)\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    241\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    244\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    245\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    247\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         value_or_values = func(trial)\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    200\u001b[39m         state = TrialState.PRUNED\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mtune_lightgbm.<locals>.objective_fn\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     51\u001b[39m y_tr, y_val = y.iloc[tr_idx], y.iloc[val_idx]\n\u001b[32m     53\u001b[39m model = (\n\u001b[32m     54\u001b[39m     LGBMRegressor(**params, n_estimators=\u001b[32m5000\u001b[39m)\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m objective == \u001b[33m\"\u001b[39m\u001b[33mtweedie\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m LGBMClassifier(**params, n_estimators=\u001b[32m5000\u001b[39m)\n\u001b[32m     57\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m model.fit(\n\u001b[32m     60\u001b[39m     X_tr, y_tr,\n\u001b[32m     61\u001b[39m     eval_set=[(X_val, y_val)],\n\u001b[32m     62\u001b[39m     eval_metric=scorer\n\u001b[32m     63\u001b[39m )\n\u001b[32m     65\u001b[39m preds = model.predict(X_val)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m scorer == \u001b[33m\"\u001b[39m\u001b[33mrmse\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28msuper\u001b[39m().fit(\n\u001b[32m   1399\u001b[39m         X,\n\u001b[32m   1400\u001b[39m         y,\n\u001b[32m   1401\u001b[39m         sample_weight=sample_weight,\n\u001b[32m   1402\u001b[39m         init_score=init_score,\n\u001b[32m   1403\u001b[39m         eval_set=eval_set,\n\u001b[32m   1404\u001b[39m         eval_names=eval_names,\n\u001b[32m   1405\u001b[39m         eval_sample_weight=eval_sample_weight,\n\u001b[32m   1406\u001b[39m         eval_init_score=eval_init_score,\n\u001b[32m   1407\u001b[39m         eval_metric=eval_metric,\n\u001b[32m   1408\u001b[39m         feature_name=feature_name,\n\u001b[32m   1409\u001b[39m         categorical_feature=categorical_feature,\n\u001b[32m   1410\u001b[39m         callbacks=callbacks,\n\u001b[32m   1411\u001b[39m         init_model=init_model,\n\u001b[32m   1412\u001b[39m     )\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = train(\n\u001b[32m   1050\u001b[39m     params=params,\n\u001b[32m   1051\u001b[39m     train_set=train_set,\n\u001b[32m   1052\u001b[39m     num_boost_round=\u001b[38;5;28mself\u001b[39m.n_estimators,\n\u001b[32m   1053\u001b[39m     valid_sets=valid_sets,\n\u001b[32m   1054\u001b[39m     valid_names=eval_names,\n\u001b[32m   1055\u001b[39m     feval=eval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   1056\u001b[39m     init_model=init_model,\n\u001b[32m   1057\u001b[39m     callbacks=callbacks,\n\u001b[32m   1058\u001b[39m )\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m booster.update(fobj=fobj)\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/DSO530/lib/python3.11/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     _LIB.LGBM_BoosterUpdateOneIter(\n\u001b[32m   4156\u001b[39m         \u001b[38;5;28mself\u001b[39m._handle,\n\u001b[32m   4157\u001b[39m         ctypes.byref(is_finished),\n\u001b[32m   4158\u001b[39m     )\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# b) Pipeline for Historically_Adjusted_Loss_Cost (HALC)\n",
    "X_halc_selected = select_features_with_rfecv(X_reg_train, Y_reg_train[\"Historically_Adjusted_Loss_Cost\"], objective=\"regression\")\n",
    "skf_halc = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_halc_params = tune_lightgbm(X_halc_selected, Y_reg_train[\"Historically_Adjusted_Loss_Cost\"], skf_halc, \"tweedie\", \"rmse\")\n",
    "X_halc_test_selected = X_reg_test[X_halc_selected.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:35:51,922] A new study created in memory with name: no-name-afa663c0-4daa-4622-afc5-c9e1d6516227\n",
      "Best trial: 0. Best value: 0.598991:   2%| | 1/60 [01:40<1:39:04, 100.75s/it, 10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:37:32,671] Trial 0 finished with value: 0.5989912307601483 and parameters: {'lr': 0.014445169854203976, 'leaves': 112, 'ff': 0.6370189931686325, 'bf': 0.8532807560122474, 'l1': 2.63828705176095, 'l2': 0.03914634118927507}. Best is trial 0 with value: 0.5989912307601483.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:   3%| | 2/60 [02:22<1:03:46, 65.97s/it, 142"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:38:14,289] Trial 1 finished with value: 0.6020954923417213 and parameters: {'lr': 0.09080648126400748, 'leaves': 33, 'ff': 0.766395757418777, 'bf': 0.9719095746657977, 'l1': 4.902992361739368, 'l2': 1.6904162014195983}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:   5%| | 3/60 [03:40<1:07:56, 71.52s/it, 220"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:39:32,420] Trial 2 finished with value: 0.5887148013455106 and parameters: {'lr': 0.06150571037357617, 'leaves': 97, 'ff': 0.5466923911544369, 'bf': 0.6301160355286437, 'l1': 1.3552642442439806, 'l2': 3.642300047665237}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:   7%| | 4/60 [05:11<1:13:49, 79.10s/it, 311"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:41:03,143] Trial 3 finished with value: 0.5960444741668738 and parameters: {'lr': 0.08936715555994391, 'leaves': 115, 'ff': 0.8282913658561987, 'bf': 0.5576818200311753, 'l1': 3.79331444941895, 'l2': 2.563665178781958}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:   8%| | 5/60 [06:20<1:09:12, 75.49s/it, 380"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:42:12,240] Trial 4 finished with value: 0.5943107292284056 and parameters: {'lr': 0.1611229620669986, 'leaves': 249, 'ff': 0.8866947562087546, 'bf': 0.6578607147993889, 'l1': 3.7936829466955606, 'l2': 1.7295675485414697}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:  10%| | 6/60 [07:48<1:11:52, 79.87s/it, 468"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:43:40,604] Trial 5 finished with value: 0.5994130599827493 and parameters: {'lr': 0.026218643768209083, 'leaves': 177, 'ff': 0.7659197137566198, 'bf': 0.5636237639250876, 'l1': 4.0855006781856, 'l2': 0.8564767402042334}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:  12%| | 7/60 [11:00<1:42:54, 116.51s/it, 66"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:46:52,544] Trial 6 finished with value: 0.5860951149624951 and parameters: {'lr': 0.05620919113031537, 'leaves': 153, 'ff': 0.9155278588077382, 'bf': 0.6238660259651629, 'l1': 1.244547002146383, 'l2': 1.038889969760099}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:  13%|▏| 8/60 [14:22<2:04:28, 143.62s/it, 86"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:50:14,227] Trial 7 finished with value: 0.5949967505424085 and parameters: {'lr': 0.029352472142950965, 'leaves': 218, 'ff': 0.5287154390602876, 'bf': 0.9115163800503033, 'l1': 1.9874921173244953, 'l2': 4.6802978131047315}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 1. Best value: 0.602095:  15%|▏| 9/60 [16:41<2:01:00, 142.35s/it, 10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:52:33,786] Trial 8 finished with value: 0.580655193980071 and parameters: {'lr': 0.15302109777175532, 'leaves': 147, 'ff': 0.9620061142643587, 'bf': 0.5598577388951961, 'l1': 0.2733986193496374, 'l2': 4.049488320083241}. Best is trial 1 with value: 0.6020954923417213.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.603705:  17%|▏| 10/60 [17:23<1:32:42, 111.24s/it, 1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:53:15,370] Trial 9 finished with value: 0.6037052283174034 and parameters: {'lr': 0.1293442514221026, 'leaves': 127, 'ff': 0.7513170082051213, 'bf': 0.9610726754029675, 'l1': 4.32053629112189, 'l2': 1.8477907117358527}. Best is trial 9 with value: 0.6037052283174034.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 9. Best value: 0.603705:  18%|▏| 11/60 [18:05<1:13:37, 90.15s/it, 10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:53:57,697] Trial 10 finished with value: 0.5956703562366874 and parameters: {'lr': 0.19892064046216357, 'leaves': 53, 'ff': 0.6614408989979601, 'bf': 0.7854701480987298, 'l1': 2.902186328609241, 'l2': 2.8719817323381935}. Best is trial 9 with value: 0.6037052283174034.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.608632:  20%|▏| 12/60 [18:36<57:44, 72.18s/it, 111"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:54:28,789] Trial 11 finished with value: 0.6086316775909035 and parameters: {'lr': 0.09450042626216652, 'leaves': 24, 'ff': 0.7291912474381439, 'bf': 0.9971563316212833, 'l1': 4.710748559379055, 'l2': 1.9274546077336518}. Best is trial 11 with value: 0.6086316775909035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.608632:  22%|▏| 13/60 [19:16<48:55, 62.46s/it, 115"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:55:08,869] Trial 12 finished with value: 0.6046883707816022 and parameters: {'lr': 0.10381205412184377, 'leaves': 69, 'ff': 0.6748312059454998, 'bf': 0.9795316941765874, 'l1': 4.9650648964009525, 'l2': 2.2536373039442967}. Best is trial 11 with value: 0.6086316775909035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 11. Best value: 0.608632:  23%|▏| 14/60 [19:50<41:17, 53.86s/it, 119"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:55:42,866] Trial 13 finished with value: 0.6080779993968219 and parameters: {'lr': 0.08849660275966191, 'leaves': 80, 'ff': 0.6577474734216049, 'bf': 0.9966023740130123, 'l1': 4.867308801739145, 'l2': 3.1563842047785045}. Best is trial 11 with value: 0.6086316775909035.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.632402:  25%|▎| 15/60 [20:22<35:23, 47.20s/it, 122"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:56:14,621] Trial 14 finished with value: 0.6324018312434373 and parameters: {'lr': 0.04077779355691961, 'leaves': 16, 'ff': 0.59462558641205, 'bf': 0.880842287616021, 'l1': 3.402467003870428, 'l2': 3.297185165203797}. Best is trial 14 with value: 0.6324018312434373.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.632402:  27%|▎| 16/60 [20:58<32:01, 43.66s/it, 125"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:56:50,064] Trial 15 finished with value: 0.6265179201063165 and parameters: {'lr': 0.0365455264670855, 'leaves': 20, 'ff': 0.5891504312267687, 'bf': 0.8578157867044721, 'l1': 3.271544082991067, 'l2': 3.568548505531864}. Best is trial 14 with value: 0.6324018312434373.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.632402:  28%|▎| 17/60 [21:36<30:05, 41.99s/it, 129"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:57:28,160] Trial 16 finished with value: 0.6305680686979626 and parameters: {'lr': 0.03204233313780679, 'leaves': 22, 'ff': 0.5875331281094813, 'bf': 0.8125046016381354, 'l1': 3.1939566931363377, 'l2': 4.558862215160811}. Best is trial 14 with value: 0.6324018312434373.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 14. Best value: 0.632402:  30%|▎| 18/60 [22:39<33:50, 48.35s/it, 135"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:58:31,335] Trial 17 finished with value: 0.6114184795413615 and parameters: {'lr': 0.021402065260597732, 'leaves': 52, 'ff': 0.6040431735549737, 'bf': 0.7429747602406799, 'l1': 3.2358359822456655, 'l2': 4.818728595231198}. Best is trial 14 with value: 0.6324018312434373.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 18. Best value: 0.634729:  32%|▎| 19/60 [23:40<35:35, 52.09s/it, 142"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 05:59:32,121] Trial 18 finished with value: 0.6347289730207339 and parameters: {'lr': 0.011035670950037636, 'leaves': 49, 'ff': 0.5679135897309378, 'bf': 0.7434429638070498, 'l1': 2.096829457485716, 'l2': 4.057510435899874}. Best is trial 18 with value: 0.6347289730207339.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.638211:  33%|▎| 20/60 [24:45<37:19, 55.98s/it, 148"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 06:00:37,175] Trial 19 finished with value: 0.6382107483853728 and parameters: {'lr': 0.010119963081896196, 'leaves': 52, 'ff': 0.5081121611375652, 'bf': 0.7147181459028071, 'l1': 1.9836507701169097, 'l2': 4.0626706557419725}. Best is trial 19 with value: 0.6382107483853728.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.638211:  35%|▎| 21/60 [26:44<48:48, 75.08s/it, 160"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 06:02:36,786] Trial 20 finished with value: 0.6144456847935608 and parameters: {'lr': 0.010008227334120968, 'leaves': 92, 'ff': 0.5142291040540798, 'bf': 0.7076156058355723, 'l1': 2.1037479044035754, 'l2': 4.258153080753306}. Best is trial 19 with value: 0.6382107483853728.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.638211:  37%|▎| 22/60 [28:44<55:57, 88.36s/it, 172"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 06:04:36,127] Trial 21 finished with value: 0.6365985640791583 and parameters: {'lr': 0.010171521160854059, 'leaves': 48, 'ff': 0.5526352248599009, 'bf': 0.7037489781620829, 'l1': 2.049140870480311, 'l2': 3.6688075913474245}. Best is trial 19 with value: 0.6382107483853728.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.638211:  38%|▍| 23/60 [29:49<50:10, 81.36s/it, 178"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 06:05:41,157] Trial 22 finished with value: 0.6330472020534054 and parameters: {'lr': 0.01033789952025201, 'leaves': 54, 'ff': 0.507056838370764, 'bf': 0.6965158519104644, 'l1': 1.529097503226497, 'l2': 3.9255395322195166}. Best is trial 19 with value: 0.6382107483853728.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 19. Best value: 0.638211:  40%|▍| 24/60 [31:03<46:35, 77.67s/it, 186"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-04-19 06:06:55,918] Trial 23 finished with value: 0.6028371145291882 and parameters: {'lr': 0.015400454643103034, 'leaves': 70, 'ff': 0.5749679663702143, 'bf': 0.7580106158784473, 'l1': 0.8049869315252502, 'l2': 4.327065159553727}. Best is trial 19 with value: 0.6382107483853728.\n",
      "Best CS params: {'lr': 0.010119963081896196, 'leaves': 52, 'ff': 0.5081121611375652, 'bf': 0.7147181459028071, 'l1': 1.9836507701169097, 'l2': 4.0626706557419725}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# c) Pipeline for Claim_Status (CS - binary classification)\n",
    "X_cs_selected = select_features_with_rfecv(X_class_train, Y_class_train[\"Claim_Status\"], objective=\"binary\")\n",
    "skf_cs = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "best_cs_params = tune_lightgbm(X_cs_selected, Y_class_train[\"Claim_Status\"], skf_cs, \"binary\", \"auc\")\n",
    "X_cs_test_selected = X_class_test[X_cs_selected.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lc = LGBMRegressor(**best_lc_params, n_estimators=5000)\n",
    "model_lc.fit(X_lc_selected, Y_reg_train[\"Loss_Cost\"])\n",
    "\n",
    "preds_lc_train = model_lc.predict(X_lc_selected)\n",
    "rmse_lc_train = rmse(Y_reg_train[\"Loss_Cost\"], preds_lc_train)\n",
    "print(f\"Train RMSE for Loss_Cost: {rmse_lc_train:.4f}\")\n",
    "\n",
    "preds_lc = model_lc.predict(X_lc_test_selected)\n",
    "rmse_lc = rmse(Y_reg_test[\"Loss_Cost\"], preds_lc)\n",
    "print(f\"Test RMSE for Loss_Cost: {rmse_lc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HALC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_halc = LGBMRegressor(**best_halc_params, n_estimators=5000)\n",
    "model_halc.fit(X_halc_selected, Y_reg_train[\"Historically_Adjusted_Loss_Cost\"])\n",
    "\n",
    "preds_halc_train = model_halc.predict(X_halc_selected)\n",
    "rmse_halc_train = rmse(Y_reg_train[\"Historically_Adjusted_Loss_Cost\"], preds_halc_train)\n",
    "print(f\"Train RMSE for Historically_Adjusted_Loss_Cost: {rmse_halc_train:.4f}\")\n",
    "\n",
    "preds_halc = model_halc.predict(X_halc_test_selected)\n",
    "rmse_halc = rmse(Y_reg_test[\"Historically_Adjusted_Loss_Cost\"], preds_halc)\n",
    "print(f\"Test RMSE for Historically_Adjusted_Loss_Cost: {rmse_halc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUC-AUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Claim Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cs = LGBMClassifier(**best_cs_params, n_estimators=5000)\n",
    "model_cs.fit(X_cs_selected, Y_class_train[\"Claim_Status\"])\n",
    "\n",
    "preds_cs_train = model_cs.predict_proba(X_cs_selected)[:, 1]\n",
    "auc_cs_train = roc_auc_score(Y_class_train[\"Claim_Status\"], preds_cs_train)\n",
    "print(f\"Train AUC for Claim_Status: {auc_cs_train:.4f}\")\n",
    "\n",
    "preds_cs = model_cs.predict_proba(X_cs_test_selected)[:, 1]\n",
    "auc_cs = roc_auc_score(Y_class_test[\"Claim_Status\"], preds_cs)\n",
    "print(f\"Test AUC for Claim_Status: {auc_cs:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DSO530",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
